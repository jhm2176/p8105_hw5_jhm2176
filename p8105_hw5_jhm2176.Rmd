---
title: "Homework 5"
author: "Jenesis Merriman"
date: "November 16, 2022"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(rvest)
library(readxl)
library(ggridges)
library(patchwork)
library(readr)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 2

This problem uses data gathered by the Washington Post on homicides across the U.S. First, I will load the raw data and describe it.

```{r}
homicides =
  read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names()
```

**Description:** The homicides dataset displays data on homicides in 50 large cities across the U.S. This dataset contains `r nrow(homicides)` rows and `r ncol(homicides)` columns, with each row representing a single reported homicide. Variables provide information about the police report, the victim, and the status of the investigation. Specifically, variables include: report id, report date, victim last name, victim first name, victim race, victim sex, victim age, city, state, latitude, longitude, and disposition. In total, `r homicides %>% filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% nrow` of the `r homicides %>% nrow` homicides in this dataset are unsolved.

Next, I will tidy the data. The following code uses `mutate` to update variables to appropriate types, convert reported_date into a more readable format, correct the capitalization of victim_first and victim_last names, and create a city_state variable that returns both city and state (e.g. “Baltimore, MD”). It also fixes one observation incorrectly noted as "Tulsa, AL," recoding it to "Tulsa, OK" since there is no Tulsa in Alabama. 

```{r}
homicides =
  read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names() %>%
  mutate(city_state = as.factor(str_c(city, state, sep = ", ")), #creates new variable
         reported_date = as.Date(as.character(reported_date),"%Y%m%d"), #date format
         victim_age = as.numeric(victim_age), #character to double
         victim_first = str_to_title(victim_first), #fixes all caps
         victim_last = str_to_title(victim_last), #fixes all caps
         victim_sex = as.factor(victim_sex), #character to factor
         victim_race = as.factor(victim_race), #character to factor
         city = as.factor(city), #character to factor
         state = as.factor(state), #character to factor
         city_state = recode(city_state, "Tulsa, AL" = "Tulsa, OK")) #CHECK DISC BOARD TO BE SURE OF THIS
```

Unsolved homicides are defined as homicides for which the disposition is “Closed without arrest” or “Open/No arrest”. With the new variable city_state, this code uses `group_by` and `summarize` to summarize within cities and obtain the total number of homicides and the number of unsolved homicides in each location. 

```{r}
city_homicides =
  homicides %>%
  group_by(city_state) %>%
  summarize(n_homicides = n(),
            n_unsolved = sum(disposition %in% c("Closed without arrest","Open/No arrest")))
```

Here, I will focus on the city of Baltimore, MD. The following code will use the `prop.test` function to estimate the proportion of homicides that are unsolved, save the output of `prop.test` as an R object, apply the `broom::tidy` to this object, and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
balt_test =
  city_homicides %>%
  filter(city_state == "Baltimore, MD") %>%
  mutate(p_test = map2(n_unsolved, n_homicides, ~ prop.test(.x, .y) %>%
                        broom::tidy())) %>% unnest()

balt_test %>% 
  select(city_state, estimate, "CI_lower" = conf.low, "CI_upper" = conf.high)
```
This next code chunk will use `purrr:map2` to apply `prop.test` to each of the cities in the dataset, and `broom::tidy` and `unnest` to extract the proportion of unsolved homicides and the confidence interval for each. The result is a tidy dataframe with estimated proportions and CIs for each city.

```{r}
city_tests =
  city_homicides %>%
  mutate(p_test = map2(n_unsolved, n_homicides, ~ prop.test(.x, .y) %>%
                        broom::tidy())) %>% unnest() %>%
  select(city_state, estimate, "CI_lower" = conf.low, "CI_upper" = conf.high)
```

Finally, the following code uses `geom_point` and `geom_errorbar` to create a plot showing the proportion estimates and confidence intervals for each city. Cities are arranged in ascending order of proportion of unsolved homicides.

```{r}
city_tests %>%
  ggplot(aes(x = reorder(city_state, +estimate), y = estimate)) +
  geom_point(show.legend = FALSE) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 60)) +
  labs(
    title = "Proportoin of unsolved homicides by city",
    x = "City",
    y = "Estimate")
```

## Problem 3
When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, I will conduct a simulation to explore power in a one-sample t-test.

First, I will generate 5000 datasets from the model x ∼ Normal [ μ , σ ] and save the mean estimates and p-values ( H : μ = 0 at α = 0.05 ) for each. I will fix n = 30, σ = 5, and set μ = 0. I will name μ as "s_mu" (sample mean) so as not to be confused with the t-test function input "mu".

The following code creates a function to simulate data from a normal distribution with the given sample size, mean, and standard deviation values and conducts a one-sample t-test for each, with the null hypothesis H : μ = 0 at α = 0.05.

```{r}
sim_mean_p = function(n = 30, s_mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = s_mu, sd = sigma),
  )
  
  sim_data %>% 
    t.test(mu = 0, conf.level = 0.95) %>%
    broom::tidy() %>% unnest()
}
```

This code generates 5000 datasets, maps my function `sim_mean_p` on each dataset, and saves the mu hat estimate and p-value for each. The resulting data frame "sim_df" contains estimates and p-values for each of the 5000 datasets.

```{r}
sim_df_1 = 
  rerun(500, sim_mean_p(s_mu = 0)) %>% #replace with n=5000
  bind_rows() %>% 
  select(estimate, p.value)
```

The following code repeats the above for μ = {1,2,3,4,5,6} and saves all estimates and p-values to the resulting data frame "sim_df_2."

```{r}
sim_df_2 = 
  tibble(s_mu = c(1:6)) %>% 
  mutate(
    output_lists = map(.x = s_mu, ~rerun(500, sim_mean_p(s_mu = .x))), #replace with 5000
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>%
  select(s_mu, estimate, p.value)
```

Finally, I will bind sim_df_2 with sim_df_1, where μ = 0, so that all values are included in the same data frame. To do so, I will need to add a "s_mu" variable to sim_df_1 so that all variables match sim_df_2. The resulting sim_df dataframe includes estimates and p-values for 35000 datasets -- 5000 for each μ = {0,1,2,3,4,5,6}.
 
```{r}
sim_df_1 = 
  sim_df_1 %>%
  mutate(s_mu = 0)

sim_df = bind_rows(sim_df_1, sim_df_2) %>% 
  relocate(s_mu)
```

### Plots

The following code creates a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis.

```{r}
power_df = 
  sim_df_2 %>%
  mutate(decision = ifelse(p.value < 0.05, "reject", "fail_to_reject")) %>%
  group_by(s_mu, decision) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = decision, values_from = count) %>%
  mutate(power = reject / 50)

power_df %>%
  ggplot(aes(x = s_mu, y = power)) + 
  geom_point() + geom_line()
```
**Description:** This plot shows a strong, positive association between effect size and power. As the effect size -- the true difference between the sample mean (s_mu) and the null mean (=0) -- increases, power increases. There also appears to be a threshold. Increases in power are significant as the sample mean approaches 4 but minimal as it exceeds 4. #ADD TEXT#

This code creates i) a plot showing the average estimate of μ̂  on the y axis and the true value of μ on the x axis and ii) a plot (or overlay on the first) showing the average estimate of μ̂  only in samples for which the null was rejected on the y axis and the true value of μ on the x axis.

```{r}
sim_df_2 %>%
  group_by(s_mu) %>%
  summarize(avg_estimate = mean(estimate)) %>%
  ggplot(aes(x = s_mu, y = avg_estimate)) +
  geom_point() + geom_line()
 

sim_df_2 %>%
  filter(p.value < 0.05) %>%
  group_by(s_mu) %>%
  summarize(avg_estimate = mean(estimate)) %>%
  ggplot(aes(x = s_mu, y = avg_estimate)) +
  geom_point() + geom_line()
  
```

**Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?**


