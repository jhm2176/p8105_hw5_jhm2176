---
title: "Homework 5"
author: "Jenesis Merriman"
date: "November 16, 2022"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(ggridges)
library(patchwork)
library(readr)
library(p8105.datasets)

knitr::opts_chunk$set(
	echo = TRUE,
	warning = FALSE,
	fig.width = 8, 
  fig.height = 6,
  out.width = "90%")

theme_set(theme_minimal() + theme(legend.position = "bottom"))

options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis")

scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

## Problem 2

This problem uses data gathered by the Washington Post on homicides across the U.S. First, I will load the raw data and describe it.

```{r}
homicides =
  read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names()
```

**Description:** The homicides dataset displays data on homicides in 50 large cities across the U.S. This dataset contains `r nrow(homicides)` rows and `r ncol(homicides)` columns, with each row representing a single reported homicide. Variables provide information about the police report, the victim, and the status of the investigation. Specifically, variables include: report id, report date, victim last name, victim first name, victim race, victim sex, victim age, city, state, latitude, longitude, and disposition. In total, `r homicides %>% filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") %>% nrow` of the `r homicides %>% nrow` homicides in this dataset are unsolved.

Next, I will tidy the data. The following code uses `mutate` to update variables to appropriate types, convert reported_date into a more readable format (YYY-MM-DD), correct the capitalization of victim_first and victim_last names, and create a city_state variable that returns both city and state (e.g. “Baltimore, MD”). It also fixes one observation incorrectly noted as occurring in "Tulsa, AL," using `mutate` and `case_when` to update this to "Tulsa, OK" since there is no Tulsa in Alabama. 

```{r}
homicides =
  read_csv("./data/homicide-data.csv") %>%
  janitor::clean_names() %>%
  mutate(state = case_when(state == "AL" & city == "Tulsa" ~ "OK", TRUE ~ state),
         city_state = as.factor(str_c(city, state, sep = ", ")), #creates new variable
         reported_date = as.Date(as.character(reported_date),"%Y%m%d"), #date format
         victim_age = as.numeric(victim_age), #character to double
         victim_first = str_to_title(victim_first), #fixes all caps
         victim_last = str_to_title(victim_last), #fixes all caps
         victim_sex = as.factor(victim_sex), #character to factor
         victim_race = as.factor(victim_race), #character to factor
         city = as.factor(city), #character to factor
         state = as.factor(state)) #character to factor
```

Unsolved homicides are defined as homicides for which the disposition is “Closed without arrest” or “Open/No arrest”. Using the new variable city_state, this code uses `group_by` and `summarize` to summarize within cities and obtain the total number of homicides and the number of unsolved homicides in each location. 

```{r}
city_homicides =
  homicides %>%
  group_by(city_state) %>%
  summarize(n_homicides = n(),
            n_unsolved = sum(disposition %in% c("Closed without arrest","Open/No arrest")))
```

Here, I will focus on the city of Baltimore, MD. The following code will use the `prop.test` function to estimate the proportion of homicides that are unsolved, save the output of `prop.test` as an R object, apply the `broom::tidy` to this object, and pull the estimated proportion and confidence intervals from the resulting tidy dataframe.

```{r}
balt_test =
  city_homicides %>%
  filter(city_state == "Baltimore, MD") %>%
  mutate(p_test = map2(n_unsolved, n_homicides, ~ prop.test(.x, .y) %>%
                        broom::tidy())) %>% unnest()

balt_test %>% 
  select(city_state, estimate, "CI_lower" = conf.low, "CI_upper" = conf.high)
```
This next code chunk will use `purrr:map2` to apply `prop.test` to each of the cities in the dataset, and `broom::tidy` and `unnest` to extract the proportion of unsolved homicides and the confidence interval for each. The result is a tidy dataframe with estimated proportions and CIs for each city.

```{r}
city_tests =
  city_homicides %>%
  mutate(p_test = map2(n_unsolved, n_homicides, ~ prop.test(.x, .y) %>%
                        broom::tidy())) %>% unnest() %>%
  select(city_state, estimate, "CI_lower" = conf.low, "CI_upper" = conf.high)
```

### Plots
Finally, the following code uses `geom_point` and `geom_errorbar` to create a plot showing the proportion estimates and confidence intervals for each city. Cities are arranged in ascending order of proportion of unsolved homicides.

```{r}
city_tests %>%
  ggplot(aes(x = reorder(city_state, +estimate), y = estimate)) +
  geom_point(show.legend = FALSE) +
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) +
  theme(axis.text.x = element_text(angle = 90)) +
  labs(
    title = "Proportoin of unsolved homicides by city",
    x = "City",
    y = "Estimate")
```

## Problem 3
When designing an experiment or analysis, a common question is whether it is likely that a true effect will be detected – put differently, whether a false null hypothesis will be rejected. The probability that a false null hypothesis is rejected is referred to as power, and it depends on several factors, including: the sample size; the effect size; and the error variance. In this problem, I will conduct a simulation to explore power in a one-sample t-test.

First, I will generate 5000 datasets from the model x ∼ Normal [ μ , σ ] and save the mean estimates and p-values ( H : μ = 0 at α = 0.05 ) for each. I will fix n = 30, σ = 5, and set μ = 0. I will name μ as "s_mu" (sample mean) so as not to be confused with the `t.test` function input "mu".

The following code creates a function to simulate data from a normal distribution with the given sample size, mean, and standard deviation values and conducts a one-sample t-test for each, with the null hypothesis H : μ = 0 at α = 0.05.

```{r}
sim_mean_p = function(n = 30, s_mu, sigma = 5) {
  
  sim_data = tibble(
    x = rnorm(n, mean = s_mu, sd = sigma),
  )
  
  sim_data %>% 
    t.test(mu = 0, conf.level = 0.95) %>%
    broom::tidy() %>% unnest()
}
```

This code generates 5000 datasets, maps my function `sim_mean_p` on each dataset, and saves the mean estimate and p-value for each. The resulting data frame "sim_df" contains estimates and p-values for each of the 5000 datasets.

```{r}
sim_df_1 = 
  rerun(500, sim_mean_p(s_mu = 0)) %>% #replace with n=5000
  bind_rows() %>% 
  select(estimate, p.value)
```

The following code repeats the above for μ = {1,2,3,4,5,6} and saves all estimates and p-values to the resulting data frame "sim_df_2."

```{r}
sim_df_2 = 
  tibble(s_mu = c(1:6)) %>% 
  mutate(
    output_lists = map(.x = s_mu, ~rerun(500, sim_mean_p(s_mu = .x))), #replace with 5000
    estimate_dfs = map(output_lists, bind_rows)) %>% 
  select(-output_lists) %>% 
  unnest(estimate_dfs) %>%
  select(s_mu, estimate, p.value)
```

Finally, I will bind sim_df_2 with sim_df_1, where μ = 0, so that all values are included in the same data frame. To do so, I will need to add a "s_mu" variable to sim_df_1 so that all variables match sim_df_2 and so that there is a clear way to distinguish datasets. The resulting sim_df dataframe includes estimates and p-values for 35000 datasets -- 5000 for each μ = {0,1,2,3,4,5,6}.
 
```{r}
sim_df_1 = 
  sim_df_1 %>%
  mutate(s_mu = 0)

sim_df = bind_rows(sim_df_1, sim_df_2) %>% 
  relocate(s_mu)
```

### Plots

The following code creates a plot showing the proportion of times the null was rejected (the power of the test) on the y axis and the true value of μ on the x axis.

```{r}
power_df = 
  sim_df %>%
  mutate(decision = ifelse(p.value < 0.05, "reject", "fail_to_reject")) %>%
  group_by(s_mu, decision) %>%
  summarize(count = n()) %>%
  pivot_wider(names_from = decision, values_from = count) %>%
  mutate(power = reject / 500)

power_df %>%
  ggplot(aes(x = s_mu, y = power)) + 
  geom_point() + geom_line()
```
**Description:** This power curve shows a positive association between effect size and power. As the effect size -- the extent of the departure from the null (μ=0) -- increases, power increases. In other words, as μ increases from 0, so does our power, until it reaches 1.0 where it remains. 

This code creates a plot showing i) the average estimate of μ̂  on the y axis and the true value of μ on the x axis and ii) the average estimate of μ̂ on the y axis and the true value of μ on the x axis only for samples for which the null was rejected .

```{r}
plot_i =
  sim_df %>%
  group_by(s_mu) %>%
  summarize(avg_estimate = mean(estimate)) %>%
  mutate(type = "all")

plot_ii =
  sim_df %>%
  filter(p.value < 0.05) %>%
  group_by(s_mu) %>%
  summarize(avg_estimate = mean(estimate)) %>%
  mutate(type = "null rejected")

plot_iii = bind_rows(plot_i, plot_ii)

plot_iii %>%
  ggplot(aes(x = s_mu, y = avg_estimate, color = type, alpha = 0.5)) +
  geom_point(aes(size = 0.5)) + geom_line() +
  guides(alpha = "none", size = "none") +
  labs(
    x = "True mean",
    y = "Mean estimate")
```

**Is the sample average of μ̂  across tests for which the null is rejected approximately equal to the true value of μ? Why or why not?**

This plot shows that the sample average of μ̂across tests for which the null is rejected is only approximately equal to the true value of μ when the true mean is 0 (null: μ=0) or greater than 2. The sample average deviates from the true mean when the true mean is 1 or 2
